{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d786aad9-99a4-4ead-980f-209696afadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydriller import Git\n",
    "from git import Repo\n",
    "import os\n",
    "import re\n",
    "from pydriller import ModificationType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d35ec5-6262-4d3f-b5dd-5cd2d0baca2d",
   "metadata": {},
   "source": [
    "## Getting Repo and commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "231621d3-e23a-44fd-bf49-a3e46f17a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url_test = \"https://github.com/nextcloud/server.git\"\n",
    "commit_hash_test = \"94975af6db1551c2d23136c2ea22866a5b416070\"\n",
    "local_repo_path_test = \"/repo/nextcloud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08772d19-d33d-4d0b-8211-b2cb3fe72b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo 'C:\\\\repo\\\\nextcloud\\\\.git'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only run this if cloning is necessary!\n",
    "#Repo.clone_from(repo_url_test, local_repo_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4db60e6-5ef9-41fa-a0be-892581b2fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Git(\"C:\\\\repo\\\\nextcloud\\\\.git\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbb010f-23d3-43a2-b7ae-fdbd9d4afe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pydriller.domain.commit.ModifiedFile object at 0x000001D43120C610>, <pydriller.domain.commit.ModifiedFile object at 0x000001D43120C340>]\n"
     ]
    }
   ],
   "source": [
    "commit = repo.get_commit(commit_hash_test)\n",
    "print(commit.modified_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3476321-812f-4a33-bf5a-27913e5260eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Lukas Reschke\n",
      "Commit Message: [stable9] Set content-type to \"application/octet-stream\"\n",
      "\n",
      "Some browsers such as Firefox on Microsoft Windows otherwise do offer to open the file directly which is kinda silly.\n",
      "\n",
      "Backport of https://github.com/nextcloud/server/pull/258\n",
      "Commit Date: 2016-06-30 13:04:54+02:00\n"
     ]
    }
   ],
   "source": [
    "#just a test to check things out\n",
    "author_name = commit.author.name\n",
    "commit_message = commit.msg\n",
    "commit_date = commit.committer_date\n",
    "\n",
    "# Printing nicely\n",
    "print(\"Author:\", author_name)\n",
    "print(\"Commit Message:\", commit_message)\n",
    "print(\"Commit Date:\", commit_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9764ba-98f0-491b-a033-73235c2578d9",
   "metadata": {},
   "source": [
    "## Getting Fix Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f38bc27a-4247-4b75-82b4-3811236d075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file):\n",
    "    file_path = file.old_path\n",
    "    # If this happens, then the file has been created in this commit\n",
    "    if file_path == None:\n",
    "        file_path = file.new_path\n",
    "    return file_path\n",
    "def is_file_valid(file_path):\n",
    "    # Extension check\n",
    "    file_extension = os.path.splitext(file_path)[1]\n",
    "    if file_extension in invalid_extensions:\n",
    "        return False\n",
    "    # Excluded files check\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    if re.match(exclusions, file_name, re.IGNORECASE):\n",
    "        return False\n",
    "    # Test files\n",
    "    file_dir = '/' + os.path.dirname(file_path) + '/'\n",
    "    directory_match = re.match(r\"^.*\\/tests?\\/.*$\", file_dir, re.IGNORECASE)\n",
    "    prefix_match = re.match(r\"^test.+\", file_name, re.IGNORECASE)\n",
    "    postfix_match = re.match(r\".+test$\", file_name, re.IGNORECASE)\n",
    "    return not (directory_match or prefix_match or postfix_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83744309-2ff4-4d9d-98d2-a2049d226913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['settings\\\\controller\\\\logsettingscontroller.php']\n"
     ]
    }
   ],
   "source": [
    "#getting the fixed files and validate them\n",
    "invalid_extensions = ('.txt', '.md', '.man', '.lang', '.loc', '.tex', '.texi', '.rst',\n",
    "'.gif', '.png', '.jpg', '.jpeg', '.svg', '.ico',\n",
    "'.css', '.scss', '.less',\n",
    "'.gradle', '.ini',\n",
    "'.zip',\n",
    "'.pdf')\n",
    "exclusions = r\"^(install|changelog(s)?|change(s)?|author(s)?|news|readme|todo|about(s)?|credit(s)?|license|release(s)?|release(s)?|release(_|-)note(s)?|version(s)?|makefile|pom|\\.git.*|\\.travis|\\.classpath|\\.project)$\"\n",
    "\n",
    "fix_files = []\n",
    "\n",
    "for mod_file in commit.modified_files:\n",
    "    file_path = get_file_name(mod_file)\n",
    "    #print(file_path)\n",
    "    if not is_file_valid(file_path):\n",
    "        continue\n",
    "    fix_files.append(file_path)\n",
    "print(fix_files)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde5df9-378d-4792-b131-e8305bf1cef4",
   "metadata": {},
   "source": [
    "## Blaming deleted lines (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a773eef1-2c61-4b5a-86b5-dcb0eabe383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_blames(blamed):\n",
    "    all_blamed_hashes = {blame for blames in blamed.values() for blame in blames}\n",
    "    print(\"*** Blamed {} commit(s)\".format(len(all_blamed_hashes)))\n",
    "    \n",
    "def blame_deleted_lines(git_repo, fix_commit, fix_files):\n",
    "    print(\"** Blaming the deleted lines...\")\n",
    "    blames = git_repo.get_commits_last_modified_lines(fix_commit)\n",
    "    blamed_from_deleted_lines = {}\n",
    "    for file, blamed_hashes in blames.items():\n",
    "        if file not in fix_files:\n",
    "            continue\n",
    "        blamed_from_deleted_lines[file] = blamed_hashes\n",
    "    print_blames(blamed_from_deleted_lines)\n",
    "    return blamed_from_deleted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18f66dc5-cd4a-4063-8a4d-78713b9cd144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Blaming the deleted lines...\n",
      "*** Blamed 1 commit(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'settings\\\\controller\\\\logsettingscontroller.php': {'b5545932e7efec24f36fae76ffe8924e31e1d55a'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blame_deleted_lines(repo, commit, fix_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e11dd4-ccb5-487b-a507-912300516705",
   "metadata": {},
   "source": [
    "## Blaming context lines (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f75b34-9c8e-40fa-ac03-f00ce3d51ca2",
   "metadata": {},
   "source": [
    "### Hunks and its validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52d0357b-89f6-475f-8795-43ca139f366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hunks(diff):\n",
    "    hunk_headers_indexes = []\n",
    "    diff_lines = diff.splitlines()\n",
    "    for index, diff_line in enumerate(diff_lines):\n",
    "        if diff_line.startswith(\"@@ -\"):\n",
    "            hunk_headers_indexes.append(index)\n",
    "    \n",
    "    hunks_text = []\n",
    "    for index, hunk_line in enumerate(hunk_headers_indexes):\n",
    "        if not index == len(hunk_headers_indexes) - 1:\n",
    "            hunk_text = diff_lines[hunk_line:hunk_headers_indexes[index + 1]]\n",
    "        else:\n",
    "            hunk_text = diff_lines[hunk_line:]\n",
    "        hunks_text.append(hunk_text)\n",
    "\n",
    "    hunks = []\n",
    "    for hunk_text in hunks_text:\n",
    "        hunk = {}\n",
    "        hunk[\"raw_text\"] = diff\n",
    "\n",
    "        hunk[\"header\"] = hunk_text[0]\n",
    "        old = re.search(\"@@ -(.*) \\+\", hunk[\"header\"]).group(1).strip().split(\",\")\n",
    "        # Ignore subprojects commit hunks, which are very rare\n",
    "        if len(old) < 2:\n",
    "            continue\n",
    "        hunk[\"old_start_line\"] = old[0]\n",
    "        hunk[\"old_length\"] = old[1]\n",
    "        new = re.search(\".*\\+(.*) @@\", hunk[\"header\"]).group(1).strip().split(\",\")\n",
    "        # Ignore very small hungs, which are very rare\n",
    "        if len(new) < 2:\n",
    "            continue\n",
    "        hunk[\"new_start_line\"] = new[0]\n",
    "        hunk[\"new_length\"] = new[1]\n",
    "        code_context = hunk[\"header\"][hunk[\"header\"].rfind(\"@\") + 2:].strip()\n",
    "        hunk[\"code_context\"] = code_context\n",
    "\n",
    "        change_block = [(i,line) for i, line in enumerate(hunk_text) if line.startswith(\"+\") or line.startswith(\"-\")]\n",
    "        start_index = change_block[0][0]\n",
    "        end_index = change_block[-1][0]\n",
    "        hunk[\"before_ctx\"] = hunk_text[1:start_index]\n",
    "        hunk[\"change_block\"] = [el[1] for el in change_block]\n",
    "        hunk[\"after_ctx\"] = hunk_text[end_index + 1:]\n",
    "        hunks.append(hunk)\n",
    "        print(\"This is what the hunks looks like... \\n\", hunks)\n",
    "    return hunks\n",
    "\n",
    "def is_valid_hunk(hunk, modified_file):\n",
    "    # We are interested in change blocks made of added lines only\n",
    "    if not all(line.startswith(\"+\") for line in hunk[\"change_block\"]):\n",
    "        print(\"In validating hunk: hunk is not valid because the lines in the change block are not all added lines\")\n",
    "        return False\n",
    "\n",
    "    # If the change block is made ONLY of the following invalid lines, it is invalid for the blame\n",
    "    first_line_block = int(hunk[\"new_start_line\"]) + len(hunk[\"before_ctx\"])\n",
    "    last_line_block = first_line_block + len(hunk[\"change_block\"]) - 1\n",
    "    invalid_lines = []\n",
    "\n",
    "    ## Step 1: useless lines are invalid\n",
    "    for index, line in enumerate(hunk[\"change_block\"]):\n",
    "        if is_useless_line(line[1:].strip()):\n",
    "            invalid_lines.append(index + first_line_block)\n",
    "    ## Step 2: if the changed method entirely fits in the changed block, then it is a new method, and its lines are all invalid\n",
    "    changed_methods = modified_file.changed_methods\n",
    "    for m in changed_methods:\n",
    "        if first_line_block <= m.start_line and m.end_line <= last_line_block:\n",
    "            invalid_lines.extend(range(m.start_line, m.end_line + 1))\n",
    "    ## Step 3: if a line doesn't belong to any method (constants, global variables, typedefs, etc.), it is invalid\n",
    "    methods = modified_file.methods\n",
    "    for i in range(first_line_block, last_line_block + 1):\n",
    "        inside = False\n",
    "        for m in methods:\n",
    "            if m.start_line <= i and i <= m.end_line:\n",
    "                inside = True\n",
    "                break\n",
    "        if not inside:\n",
    "            invalid_lines.append(i)\n",
    "\n",
    "    # Remove duplicates and sort\n",
    "    invalid_lines = sorted(list(set(invalid_lines)))\n",
    "    if invalid_lines == list(range(first_line_block, last_line_block + 1)):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42e9b42c-8d8e-404c-8f0a-4b8c4a7dac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blame_context_lines(git_repo, fix_commit, fix_files):\n",
    "    print(\"** Blaming the context lines for add-only hunks...\")\n",
    "    blamed_from_context_lines = {}\n",
    "    for modified_file in fix_commit.modified_files:\n",
    "        filepath = get_file_name(modified_file)\n",
    "        # We don't consider new files because they won't blame anything\n",
    "        if modified_file.change_type == ModificationType.ADD:\n",
    "            print(\"In blaming context lines: modified file is a new file\")\n",
    "            continue\n",
    "        # Consider only the files previously appoved\n",
    "        if not filepath in fix_files:\n",
    "            print(\"In blaming context lines: file path is not in fix files\")\n",
    "            continue\n",
    "        hunks = parse_hunks(modified_file.diff)\n",
    "        blamed_hashes = set()\n",
    "        for hunk in hunks:\n",
    "            # Do not consider invalid hunks\n",
    "            if not is_valid_hunk(hunk, modified_file):\n",
    "                print(\"In blaming context lines: hunk is not valid\")\n",
    "                continue\n",
    "\n",
    "            # At this point, we are sure that the hunk is made of added lines only, we can safely consider the \"old start line + offset\" to blame the entire hunk context only\n",
    "            start_line = str(hunk[\"old_start_line\"])\n",
    "            offset = \"+\" + hunk[\"old_length\"]\n",
    "            # If the file is not found in the previous commits, it may be due to, rare, double renaming: we ignore these cases\n",
    "            try:\n",
    "                blame_output = git_repo.repo.git.blame(\"-w\", \"-c\", \"-l\", \"-L\", start_line + \",\" + offset, fix_commit.hash + \"^\", \"--\", filepath)\n",
    "            except GitCommandError:\n",
    "                print(GitCommandError)\n",
    "                continue\n",
    "            print(\"In blaming context lines: About to make the blames...\")\n",
    "            blamed_hashes = set()\n",
    "            for blame_line in blame_output.splitlines():\n",
    "                blame_line_split = blame_line.split(\"\\t\")\n",
    "                blamed_hash = blame_line_split[0]\n",
    "                #line_number = blame_line_split[3].split(\")\")[0]\n",
    "                code = blame_line_split[3].split(\")\")[1].strip()\n",
    "                # Should an empty line be blamed, ignore it\n",
    "                if not code:\n",
    "                    continue\n",
    "                blamed_hashes.add(blamed_hash)\n",
    "            blamed_from_context_lines[filepath] = blamed_hashes\n",
    "    print_blames(blamed_from_context_lines)\n",
    "    return blamed_from_context_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14b41e0a-c967-41f7-a0f8-f0a83c39bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Blaming the context lines for add-only hunks...\n",
      "This is what the hunks looks like... \n",
      " [{'raw_text': '@@ -103,7 +103,8 @@ class LogSettingsController extends Controller {\\n \\t */\\n \\tpublic function download() {\\n \\t\\t$resp = new StreamResponse(\\\\OC_Log_Owncloud::getLogFilePath());\\n-\\t\\t$resp->addHeader(\\'Content-Disposition\\', \\'attachment; filename=\"owncloud.log\"\\');\\n+\\t\\t$resp->addHeader(\\'Content-Type\\', \\'application/octet-stream\\');\\n+\\t\\t$resp->addHeader(\\'Content-Disposition\\', \\'attachment; filename=\"nextcloud.log\"\\');\\n \\t\\treturn $resp;\\n \\t}\\n }\\n', 'header': '@@ -103,7 +103,8 @@ class LogSettingsController extends Controller {', 'old_start_line': '103', 'old_length': '7', 'new_start_line': '103', 'new_length': '8', 'code_context': 'class LogSettingsController extends Controller {', 'before_ctx': [' \\t */', ' \\tpublic function download() {', ' \\t\\t$resp = new StreamResponse(\\\\OC_Log_Owncloud::getLogFilePath());'], 'change_block': ['-\\t\\t$resp->addHeader(\\'Content-Disposition\\', \\'attachment; filename=\"owncloud.log\"\\');', \"+\\t\\t$resp->addHeader('Content-Type', 'application/octet-stream');\", '+\\t\\t$resp->addHeader(\\'Content-Disposition\\', \\'attachment; filename=\"nextcloud.log\"\\');'], 'after_ctx': [' \\t\\treturn $resp;', ' \\t}', ' }']}]\n",
      "In validating hunk: hunk is not valid because the lines in the change block are not all added lines\n",
      "In blaming context lines: hunk is not valid\n",
      "In blaming context lines: file path is not in fix files\n",
      "*** Blamed 0 commit(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blame_context_lines(repo, commit, fix_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
